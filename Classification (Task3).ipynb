{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c221b2c-f9b5-4846-9e9c-456ea54df1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Arabic-Stopwords in c:\\users\\huzyfa\\anaconda3\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: pyarabic>=0.6.2 in c:\\users\\huzyfa\\anaconda3\\lib\\site-packages (from Arabic-Stopwords) (0.6.15)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\huzyfa\\anaconda3\\lib\\site-packages (from pyarabic>=0.6.2->Arabic-Stopwords) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# importing the needed libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import perf_counter, time\n",
    "import joblib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, make_scorer\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "!pip install Arabic-Stopwords\n",
    "import arabicstopwords.arabicstopwords as stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b76191e-7475-44b8-993b-98dad37632e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "\n",
    "# fix random number generation aka regenerate the same random numbers every time (such as weight and bias initialization )\n",
    "def set_random_seed(seed):\n",
    "    \"\"\"Set random seed, for python, numpy\n",
    "\n",
    "    Args:\n",
    "        seed (int): Seed to be used.\n",
    "    \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "set_random_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43c8236-30c0-4c17-8ea0-b512f44317eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the files\n",
    "df1 = pd.read_csv('./resourses/archive/stories_art-et-culture.csv', index_col='id')\n",
    "df2 = pd.read_csv('./resourses/archive/stories_economie.csv', index_col='id')\n",
    "df3 = pd.read_csv('./resourses/archive/stories_faits-divers.csv', index_col='id')\n",
    "df4 = pd.read_csv('./resourses/archive/stories_marocains-du-monde.csv', index_col='id')\n",
    "df5 = pd.read_csv('./resourses/archive/stories_medias.csv', index_col='id')\n",
    "df6 = pd.read_csv('./resourses/archive/stories_orbites.csv', index_col='id')\n",
    "df7 = pd.read_csv('./resourses/archive/stories_politique.csv', index_col='id')\n",
    "df8 = pd.read_csv('./resourses/archive/stories_regions.csv', index_col='id')\n",
    "df9 = pd.read_csv('./resourses/archive/stories_societe.csv', index_col='id')\n",
    "df10 = pd.read_csv('./resourses/archive/stories_sport.csv', index_col='id')\n",
    "df11 = pd.read_csv('./resourses/archive/stories_tamazight.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a4233c-b4e8-4d35-9220-510b644ead55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>story</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f06aa998054e11eba66e646e69d991ea</th>\n",
       "      <td>0</td>\n",
       "      <td>\"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 23:19</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1cf1b9c054e11ebb718646e69d991ea</th>\n",
       "      <td>1</td>\n",
       "      <td>مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 07:26</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2d282a4054e11eb800f646e69d991ea</th>\n",
       "      <td>2</td>\n",
       "      <td>فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا...</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 04:00</td>\n",
       "      <td>عفيفة الحسينات*</td>\n",
       "      <td>تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3f46cac054e11eba403646e69d991ea</th>\n",
       "      <td>3</td>\n",
       "      <td>\"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا...</td>\n",
       "      <td>الجمعة 02 أكتوبر 2020 - 02:00</td>\n",
       "      <td>حاورَها: وائل بورشاشن</td>\n",
       "      <td>مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f50f0476054e11eba31b646e69d991ea</th>\n",
       "      <td>4</td>\n",
       "      <td>مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\"</td>\n",
       "      <td>الخميس 01 أكتوبر 2020 - 19:40</td>\n",
       "      <td>هسبريس من الرباط</td>\n",
       "      <td>أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...</td>\n",
       "      <td>art-et-culture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Unnamed: 0  \\\n",
       "id                                             \n",
       "f06aa998054e11eba66e646e69d991ea           0   \n",
       "f1cf1b9c054e11ebb718646e69d991ea           1   \n",
       "f2d282a4054e11eb800f646e69d991ea           2   \n",
       "f3f46cac054e11eba403646e69d991ea           3   \n",
       "f50f0476054e11eba31b646e69d991ea           4   \n",
       "\n",
       "                                                                              title  \\\n",
       "id                                                                                    \n",
       "f06aa998054e11eba66e646e69d991ea     \"بيت الشعر\" يسائل وزير الثقافة عن كوابيس سوداء   \n",
       "f1cf1b9c054e11ebb718646e69d991ea       مهرجان \"سينما المؤلّف\" يستحضر روح ثريا جبران   \n",
       "f2d282a4054e11eb800f646e69d991ea  فيلم \"بدون عنف\" لهشام العسري ..\"كعب الحذاء ووا...   \n",
       "f3f46cac054e11eba403646e69d991ea  \"تنين ووهان\" .. مريم أيت أحمد توقِّع أولى \"روا...   \n",
       "f50f0476054e11eba31b646e69d991ea        مسكر يتخلّى عن دعم \"الوزارة\" بسبب \"الجمهور\"   \n",
       "\n",
       "                                                           date  \\\n",
       "id                                                                \n",
       "f06aa998054e11eba66e646e69d991ea  الجمعة 02 أكتوبر 2020 - 23:19   \n",
       "f1cf1b9c054e11ebb718646e69d991ea  الجمعة 02 أكتوبر 2020 - 07:26   \n",
       "f2d282a4054e11eb800f646e69d991ea  الجمعة 02 أكتوبر 2020 - 04:00   \n",
       "f3f46cac054e11eba403646e69d991ea  الجمعة 02 أكتوبر 2020 - 02:00   \n",
       "f50f0476054e11eba31b646e69d991ea  الخميس 01 أكتوبر 2020 - 19:40   \n",
       "\n",
       "                                                 author  \\\n",
       "id                                                        \n",
       "f06aa998054e11eba66e646e69d991ea       هسبريس من الرباط   \n",
       "f1cf1b9c054e11ebb718646e69d991ea       هسبريس من الرباط   \n",
       "f2d282a4054e11eb800f646e69d991ea        عفيفة الحسينات*   \n",
       "f3f46cac054e11eba403646e69d991ea  حاورَها: وائل بورشاشن   \n",
       "f50f0476054e11eba31b646e69d991ea       هسبريس من الرباط   \n",
       "\n",
       "                                                                              story  \\\n",
       "id                                                                                    \n",
       "f06aa998054e11eba66e646e69d991ea  وجه \"بيت الشعر في المغرب\" إلى وزير الثقافة وال...   \n",
       "f1cf1b9c054e11ebb718646e69d991ea  في ظلّ استمرار حالة الطوارئ الصحية المرتبطة بج...   \n",
       "f2d282a4054e11eb800f646e69d991ea  تشير مشاهدة فيلم قصير ضمن الثلاثية الأخيرة للم...   \n",
       "f3f46cac054e11eba403646e69d991ea  مِن قَلب أيّام \"الحَجْر\"، رأتِ النّورَ الفصول ...   \n",
       "f50f0476054e11eba31b646e69d991ea  أعلن الفنان المغربيّ سعيد مسكر تخليه عن مبلغ ا...   \n",
       "\n",
       "                                           topic  \n",
       "id                                                \n",
       "f06aa998054e11eba66e646e69d991ea  art-et-culture  \n",
       "f1cf1b9c054e11ebb718646e69d991ea  art-et-culture  \n",
       "f2d282a4054e11eb800f646e69d991ea  art-et-culture  \n",
       "f3f46cac054e11eba403646e69d991ea  art-et-culture  \n",
       "f50f0476054e11eba31b646e69d991ea  art-et-culture  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23035001-644a-4551-b0bc-af87d893a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                             \"\"\", re.VERBOSE)\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    '''this function to remove diacritics'''\n",
    "    \n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    return text\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    '''this function to convert some special arabic characters into more general equivalent ones'''\n",
    "    \n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)   # i keep this because this one contains useful feature as specially iraq uses this character\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    '''this function to remove punctuation'''\n",
    "    \n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "# def remove_repeating_char(text):\n",
    "#     return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    '''this function is to remove stop-words using nltk arabic-stopwords'''\n",
    "    \n",
    "    stop_words = list(stopwords.words('arabic'))\n",
    "    return ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "# alternative method to remove_stop_words\n",
    "def remove_stop_words(text):\n",
    "    '''this function is to remove stop-words'''\n",
    "    \n",
    "    return \" \".join(word for word in text.split() if not stp.is_stop(word))\n",
    "\n",
    "def clean_text(text):\n",
    "    # t = re.sub(r'#', ' ', t) # replace '#' with space\n",
    "    # t = re.sub(r'_', ' ', t)    # replace '_' with space\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF]', ' ', text) # remove all characters except arabic ones\n",
    "    text = remove_diacritics(text) \n",
    "    text = remove_punctuations(text) # remove the remained punctuations, actually the remains are only \"\"\" ?,; \"\"\"\n",
    "    text = normalize_arabic(text)    # replace speacial arabic characters with some how general ones\n",
    "    text = re.sub(r' +', ' ', text)  # remove multiple spaces, also can done with re.sub(r'/\\s\\s+/g', ' ', text)\n",
    "    text = remove_stop_words(text)\n",
    "    # text = remove_repeating_char(text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656d0ec6-b2cf-4716-8890-0ef730051203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making preprocessing to remove unwanted symbols\n",
    "df1[\"preprocessed_story\"] = [clean_text(text) for text in df1[\"story\"]]\n",
    "df2[\"preprocessed_story\"] = [clean_text(text) for text in df2[\"story\"]]\n",
    "df3[\"preprocessed_story\"] = [clean_text(text) for text in df3[\"story\"]]\n",
    "df4[\"preprocessed_story\"] = [clean_text(text) for text in df4[\"story\"]]\n",
    "df5[\"preprocessed_story\"] = [clean_text(text) for text in df5[\"story\"]]\n",
    "df6[\"preprocessed_story\"] = [clean_text(text) for text in df6[\"story\"]]\n",
    "df7[\"preprocessed_story\"] = [clean_text(text) for text in df7[\"story\"]]\n",
    "df8[\"preprocessed_story\"] = [clean_text(text) for text in df8[\"story\"]]\n",
    "df9[\"preprocessed_story\"] = [clean_text(text) for text in df9[\"story\"]]\n",
    "df10[\"preprocessed_story\"] = [clean_text(text) for text in df10[\"story\"]]\n",
    "df11[\"preprocessed_story\"] = [clean_text(text) for text in df11[\"story\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9d490f-b9d2-4a28-907b-b0f399693eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the 11 files\n",
    "df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11], axis=0, ignore_index=False)\n",
    "df.index.name=\"id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c60d3b56-62e2-42db-b187-e5d9d17e7ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>story</th>\n",
       "      <th>topic</th>\n",
       "      <th>preprocessed_story</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75b0b940055811ebb2ff646e69d991ea</th>\n",
       "      <td>995</td>\n",
       "      <td>نشطاء أمازيغ يدافعون عن \"الحقّ\" في استقبال إسر...</td>\n",
       "      <td>الثلاثاء 10 شتنبر 2013 - 02:00</td>\n",
       "      <td>هسبريس ـ ميمون أم العيد</td>\n",
       "      <td>دافع ناشطون أمازيغ استقبلوا أخيرا وفدا من الطل...</td>\n",
       "      <td>tamazight</td>\n",
       "      <td>دافع ناشطون امازيغ استقبلوا اخيرا وفدا الطلبه ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775c3440055811ebbc60646e69d991ea</th>\n",
       "      <td>996</td>\n",
       "      <td>شاعرة أمازيغية تعتصم بالمطار لرفض استمارتها بـ...</td>\n",
       "      <td>الاثنين 09 شتنبر 2013 - 08:20</td>\n",
       "      <td>هسبريس ـ عبد المغيث جبران</td>\n",
       "      <td>خاضت الشاعرة الأمازيغية ملكية مزان اعتصاما لمد...</td>\n",
       "      <td>tamazight</td>\n",
       "      <td>خاضت الشاعره الامازيغيه ملكيه مزان اعتصاما لمد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78fea9ba055811eb9e32646e69d991ea</th>\n",
       "      <td>997</td>\n",
       "      <td>وفد إسرائيلي يزور المغرب ويلتقي نشطاء أمازيغ ب...</td>\n",
       "      <td>الثلاثاء 03 شتنبر 2013 - 16:24</td>\n",
       "      <td>هسبريس - ماجدة أيت لكتاوي</td>\n",
       "      <td>أدانت المنسقية الوطنية للمبادرة الطلابية ضد ال...</td>\n",
       "      <td>tamazight</td>\n",
       "      <td>ادانت المنسقيه الوطنيه للمبادره الطلابيه ضد ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7a58d38c055811ebb9c9646e69d991ea</th>\n",
       "      <td>998</td>\n",
       "      <td>نقاش أمازيغيّ مؤنّث بطنجة يذكّر بكَوْن الحقوق ...</td>\n",
       "      <td>السبت 17 غشت 2013 - 10:30</td>\n",
       "      <td>هسبريس من طنجة</td>\n",
       "      <td>طالبت الناشطة الأمازيغية مريم الدمناتي بضرورة ...</td>\n",
       "      <td>tamazight</td>\n",
       "      <td>طالبت الناشطه الامازيغيه مريم الدمناتي بضروره ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7b769274055811eba13c646e69d991ea</th>\n",
       "      <td>999</td>\n",
       "      <td>أمازيغ يقتحمون مقر البرلمان الليبي مطالبين بـ\"...</td>\n",
       "      <td>الثلاثاء 13 غشت 2013 - 21:00</td>\n",
       "      <td>محمد الناجم من طرابلس*</td>\n",
       "      <td>اقتحم المئات من المتظاهرين المنحدرين من الأقلي...</td>\n",
       "      <td>tamazight</td>\n",
       "      <td>اقتحم المءات المتظاهرين المنحدرين الاقليات الا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Unnamed: 0  \\\n",
       "id                                             \n",
       "75b0b940055811ebb2ff646e69d991ea         995   \n",
       "775c3440055811ebbc60646e69d991ea         996   \n",
       "78fea9ba055811eb9e32646e69d991ea         997   \n",
       "7a58d38c055811ebb9c9646e69d991ea         998   \n",
       "7b769274055811eba13c646e69d991ea         999   \n",
       "\n",
       "                                                                              title  \\\n",
       "id                                                                                    \n",
       "75b0b940055811ebb2ff646e69d991ea  نشطاء أمازيغ يدافعون عن \"الحقّ\" في استقبال إسر...   \n",
       "775c3440055811ebbc60646e69d991ea  شاعرة أمازيغية تعتصم بالمطار لرفض استمارتها بـ...   \n",
       "78fea9ba055811eb9e32646e69d991ea  وفد إسرائيلي يزور المغرب ويلتقي نشطاء أمازيغ ب...   \n",
       "7a58d38c055811ebb9c9646e69d991ea  نقاش أمازيغيّ مؤنّث بطنجة يذكّر بكَوْن الحقوق ...   \n",
       "7b769274055811eba13c646e69d991ea  أمازيغ يقتحمون مقر البرلمان الليبي مطالبين بـ\"...   \n",
       "\n",
       "                                                            date  \\\n",
       "id                                                                 \n",
       "75b0b940055811ebb2ff646e69d991ea  الثلاثاء 10 شتنبر 2013 - 02:00   \n",
       "775c3440055811ebbc60646e69d991ea   الاثنين 09 شتنبر 2013 - 08:20   \n",
       "78fea9ba055811eb9e32646e69d991ea  الثلاثاء 03 شتنبر 2013 - 16:24   \n",
       "7a58d38c055811ebb9c9646e69d991ea       السبت 17 غشت 2013 - 10:30   \n",
       "7b769274055811eba13c646e69d991ea    الثلاثاء 13 غشت 2013 - 21:00   \n",
       "\n",
       "                                                     author  \\\n",
       "id                                                            \n",
       "75b0b940055811ebb2ff646e69d991ea    هسبريس ـ ميمون أم العيد   \n",
       "775c3440055811ebbc60646e69d991ea  هسبريس ـ عبد المغيث جبران   \n",
       "78fea9ba055811eb9e32646e69d991ea  هسبريس - ماجدة أيت لكتاوي   \n",
       "7a58d38c055811ebb9c9646e69d991ea             هسبريس من طنجة   \n",
       "7b769274055811eba13c646e69d991ea     محمد الناجم من طرابلس*   \n",
       "\n",
       "                                                                              story  \\\n",
       "id                                                                                    \n",
       "75b0b940055811ebb2ff646e69d991ea  دافع ناشطون أمازيغ استقبلوا أخيرا وفدا من الطل...   \n",
       "775c3440055811ebbc60646e69d991ea  خاضت الشاعرة الأمازيغية ملكية مزان اعتصاما لمد...   \n",
       "78fea9ba055811eb9e32646e69d991ea  أدانت المنسقية الوطنية للمبادرة الطلابية ضد ال...   \n",
       "7a58d38c055811ebb9c9646e69d991ea  طالبت الناشطة الأمازيغية مريم الدمناتي بضرورة ...   \n",
       "7b769274055811eba13c646e69d991ea  اقتحم المئات من المتظاهرين المنحدرين من الأقلي...   \n",
       "\n",
       "                                      topic  \\\n",
       "id                                            \n",
       "75b0b940055811ebb2ff646e69d991ea  tamazight   \n",
       "775c3440055811ebbc60646e69d991ea  tamazight   \n",
       "78fea9ba055811eb9e32646e69d991ea  tamazight   \n",
       "7a58d38c055811ebb9c9646e69d991ea  tamazight   \n",
       "7b769274055811eba13c646e69d991ea  tamazight   \n",
       "\n",
       "                                                                 preprocessed_story  \n",
       "id                                                                                   \n",
       "75b0b940055811ebb2ff646e69d991ea  دافع ناشطون امازيغ استقبلوا اخيرا وفدا الطلبه ...  \n",
       "775c3440055811ebbc60646e69d991ea  خاضت الشاعره الامازيغيه ملكيه مزان اعتصاما لمد...  \n",
       "78fea9ba055811eb9e32646e69d991ea  ادانت المنسقيه الوطنيه للمبادره الطلابيه ضد ال...  \n",
       "7a58d38c055811ebb9c9646e69d991ea  طالبت الناشطه الامازيغيه مريم الدمناتي بضروره ...  \n",
       "7b769274055811eba13c646e69d991ea  اقتحم المءات المتظاهرين المنحدرين الاقليات الا...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "712ae1b2-0cbc-4f02-a87f-f3eabe329e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting each file into 80% training-set and the last 20% for testing-set\n",
    "df1_train, df1_test = train_test_split(df1, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "df2_train, df2_test = train_test_split(df2, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "df3_train, df3_test = train_test_split(df3, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "df4_train, df4_test = train_test_split(df4, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "df5_train, df5_test = train_test_split(df5, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "df6_train, df6_test = train_test_split(df6, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "df7_train, df7_test = train_test_split(df7, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "df8_train, df8_test = train_test_split(df8, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "df9_train, df9_test = train_test_split(df9, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "df10_train, df10_test = train_test_split(df10, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "df11_train, df11_test = train_test_split(df11, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Alternative way to get the same result using pandas\n",
    "# df1_train, df1_test = df1.head(800), df1.tail(200)\n",
    "# df2_train, df2_test = df2.head(800), df2.tail(200)\n",
    "# df3_train, df3_test = df3.head(800), df3.tail(200)\n",
    "# df4_train, df4_test = df4.head(800), df4.tail(200)\n",
    "# df5_train, df5_test = df5.head(800), df5.tail(200)\n",
    "# df6_train, df6_test = df6.head(800), df6.tail(200)\n",
    "# df7_train, df7_test = df7.head(800), df7.tail(200)\n",
    "# df8_train, df8_test = df8.head(800), df8.tail(200)\n",
    "# df9_train, df9_test = df9.head(800), df9.tail(200)\n",
    "# df10_train, df10_test = df10.head(800), df10.tail(200)\n",
    "# df11_train, df11_test = df11.head(800), df11.tail(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f1ccf2-40a6-4bec-a7ea-2f797bdfaad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the 11 training dfs\n",
    "df_train = pd.concat([df1_train, df2_train, df3_train, df4_train, df5_train, df6_train,\n",
    "                      df7_train, df8_train, df9_train, df10_train, df11_train], axis=0, ignore_index=False)\n",
    "\n",
    "# separate the label from the feature_column\n",
    "y_train = df_train.pop('topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cf27ffc-8f80-48a5-bad0-42717b9b30b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the 11 training dfs\n",
    "df_test = pd.concat([df1_test, df2_test, df3_test, df4_test, df5_test, df6_test,\n",
    "                      df7_test, df8_test, df9_test, df10_test, df11_test], axis=0, ignore_index=False)\n",
    "\n",
    "# separate the label from the feature_column\n",
    "y_test = df_test.pop('topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298aa655-8ab8-45e5-b931-17a5149e0271",
   "metadata": {},
   "source": [
    "#### **i will use only the story column as i expect that it has the most useful information i need to do classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b31bc1d-a37a-4770-a1c9-3cc39f666826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "f06aa998054e11eba66e646e69d991ea    وجه بيت الشعر المغرب الي وزير الثقافه والشباب ...\n",
       "f1cf1b9c054e11ebb718646e69d991ea    استمرار حاله الطوارء الصحيه المرتبطه بجاءحه كو...\n",
       "f2d282a4054e11eb800f646e69d991ea    تشير مشاهده فيلم قصير الثلاثيه الاخيره للمخرج ...\n",
       "f3f46cac054e11eba403646e69d991ea    قلب ايام الحجر رات النور الفصول الاولي روايه م...\n",
       "f50f0476054e11eba31b646e69d991ea    اعلن الفنان المغربي سعيد مسكر تخليه مبلغ الدعم...\n",
       "                                                          ...                        \n",
       "944a0bb4055711ebb1b9646e69d991ea    طالبت العصبه الامازيغيه لحقوق الانسان الحكومه ...\n",
       "953dd0ac055711ebb532646e69d991ea    اطار تخليد جمعيه تامزغا بمدريد لاحتفالات السنه...\n",
       "96224fa4055711eb90c1646e69d991ea    الوقت تنظر الحركه الامازيغيه الرضا الي موقف حز...\n",
       "96f78a2e055711eb969b646e69d991ea    قريه ملاعب الصغيره كلم الرشيديه حجمها الكبيره ...\n",
       "97edc77a055711ebb043646e69d991ea    طالب خالد الزراري رءيس الكونغرس العالمي الاماز...\n",
       "Name: preprocessed_story, Length: 8800, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting only the preprocessed_topic column\n",
    "df_train = df_train['preprocessed_story']\n",
    "# or we may squeeze it, the goal is to convert it into pd.Series\n",
    "# df_train = df_train.squeeze()\n",
    "\n",
    "# showing the first 5 rows after selecting of preprocessed_story to make sure that every thing is go as expected\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b98120-941a-4769-828f-98bb5317ad8e",
   "metadata": {},
   "source": [
    "- **NOTE:- the used features is my implementation of a paper published that get the SOTA in classifying tweets into it's arabic dialectic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2198372-5146-47dd-a4a4-75e397d97ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing support vector machine model\n",
    "# svm = NuSVC(random_state=seed, \n",
    "#             # kernel=\"linear\"\n",
    "#            )\n",
    "\n",
    "svm = SVC(random_state=seed)\n",
    "\n",
    "# creating pipeline of the needed feature \n",
    "pipeline = Pipeline([\n",
    "                     ('cw26', FeatureUnion([\n",
    "                                            ('word_features', Pipeline([\n",
    "                                                                        ('ngram_w', CountVectorizer(ngram_range=(2, 3),\n",
    "                                                                                                   analyzer='word')),\n",
    "                                                                        ('tfidf_w', TfidfTransformer())\n",
    "                                                                        ])),\n",
    "                                            ('char_features', Pipeline([\n",
    "                                                                        ('ngram_c', CountVectorizer(ngram_range=(2, 3), \n",
    "                                                                                                   analyzer='char')),\n",
    "                                                                        ('tfidf_c', TfidfTransformer())\n",
    "                                                                        ])),\n",
    "                                             ])),\n",
    "                     ('svm', svm)\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51d9b7fb-aa4d-4aaf-a39d-278db667d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\"svm__kernel\" : ['linear', 'rbf']}\n",
    "\n",
    "def customized_func(ytrue, ypred):\n",
    "    '''this customized function is just an example of how to use customized evaluation function'''\n",
    "    \n",
    "    return f1_score(ytrue, ypred)\n",
    "\n",
    "refit = \"f1\"\n",
    "scr = refit\n",
    "scoring={\"precision\":make_scorer(precision_score), \n",
    "         \"recall\":make_scorer(recall_score),\n",
    "         \"f1\":make_scorer(f1_score), \n",
    "         \"score\":make_scorer(accuracy_score), \n",
    "         \"f1_scored\": make_scorer(customized_func)}\n",
    "         \n",
    "# model = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, \n",
    "model = GridSearchCV(estimator=pipeline, \n",
    "                     param_grid=param_grid,                          \n",
    "                     cv=2, \n",
    "                     scoring=scoring, \n",
    "                     refit=refit, \n",
    "                     n_jobs=1, \n",
    "                     return_train_score=True, \n",
    "                     verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4c6e0ef-a08f-4cee-86fc-640a056827dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin moment = 117.2255431\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1776, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1563, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1381, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1776, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1563, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1381, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END svm__kernel=linear; f1: (train=nan, test=nan) f1_scored: (train=nan, test=nan) precision: (train=nan, test=nan) recall: (train=nan, test=nan) score: (train=nan, test=nan) total time=11.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1776, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1563, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1381, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1776, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1563, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1381, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END svm__kernel=linear; f1: (train=nan, test=nan) f1_scored: (train=nan, test=nan) precision: (train=nan, test=nan) recall: (train=nan, test=nan) score: (train=nan, test=nan) total time=11.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1776, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1563, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1381, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1776, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1563, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1381, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END svm__kernel=rbf; f1: (train=nan, test=nan) f1_scored: (train=nan, test=nan) precision: (train=nan, test=nan) recall: (train=nan, test=nan) score: (train=nan, test=nan) total time=12.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1776, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1563, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1381, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 106, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1776, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1563, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1381, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END svm__kernel=rbf; f1: (train=nan, test=nan) f1_scored: (train=nan, test=nan) precision: (train=nan, test=nan) recall: (train=nan, test=nan) score: (train=nan, test=nan) total time=12.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huzyfa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completion moment = 5433.1975275\n",
      "elabsed time is 1.0 hours: 28.0 minuts\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Boolean index has wrong length: 7 instead of 51",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8424/2558553404.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"elabsed time is {elapsed_time//60} hours: {elapsed_time%60} minuts\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m results = pd.DataFrame(model.cv_results_\n\u001b[0m\u001b[0;32m     11\u001b[0m                       ).sort_values(by=f\"rank_test_{scr}\").loc[:,df.columns.str.contains('rank')]\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    923\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1107\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1109\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    804\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m             \u001b[1;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m             \u001b[1;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1142\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1144\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1145\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m    946\u001b[0m         \u001b[1;31m# caller is responsible for ensuring non-None axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m         \u001b[0minds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2399\u001b[0m         \u001b[1;31m# key may contain nan elements, check_array_indexer needs bool array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2400\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2401\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_array_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexers.py\u001b[0m in \u001b[0;36mcheck_array_indexer\u001b[1;34m(array, indexer)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;31m# GH26658\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             raise IndexError(\n\u001b[0m\u001b[0;32m    562\u001b[0m                 \u001b[1;34mf\"Boolean index has wrong length: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                 \u001b[1;34mf\"{len(indexer)} instead of {len(array)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Boolean index has wrong length: 7 instead of 51"
     ]
    }
   ],
   "source": [
    "begin_moment = perf_counter()\n",
    "print(f\"begin moment = {begin_moment}\")\n",
    "model.get_params()\n",
    "model.fit(df_train, y_train)\n",
    "completion_moment = perf_counter()\n",
    "elapsed_time = (completion_moment-begin_moment)//60\n",
    "print(f\"completion moment = {completion_moment}\")\n",
    "print(f\"elabsed time is {elapsed_time//60} hours: {elapsed_time%60} minuts\")\n",
    "\n",
    "results = pd.DataFrame(model.cv_results_\n",
    "                      )#.sort_values(by=f\"rank_test_{scr}\").loc[:,df.columns.str.contains('rank')]\n",
    "\n",
    "# results[:5].filter(regex='rank | mean | params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f0c9a0f-cd48-4488-862f-3bd2ffd845bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13939e7c-6af9-4ad2-ad06-d3e1a32eae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './resourses/finalized_model.sav'\n",
    "\n",
    "# save the model to disk\n",
    "joblib.dump(model, filename)\n",
    "\n",
    "# # some time later...\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "\n",
    "###########################################################################\n",
    "# alternative saving method\n",
    "# import pickle\n",
    "# # # save the model to disk\n",
    "# filename = 'finalized_model.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# # some time later...\n",
    "\n",
    "# # load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6baa569-b509-47a6-9793-b8999075e75a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11336/913623915.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m results = pd.DataFrame(model.cv_results_\n\u001b[0m\u001b[0;32m      2\u001b[0m                       ).sort_values(by=f\"rank_test_{scr}\").loc[:,df.columns.str.contains('rank')]\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rank | mean | params'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(model.cv_results_\n",
    "                      ).sort_values(by=f\"rank_test_{scr}\").loc[:,df.columns.str.contains('rank')]\n",
    "\n",
    "results[:5].filter(regex='rank | mean | params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8833baf-ca41-4694-8aee-99c1c897ab78",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11336/962467392.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9e5e81e-2207-4b35-9650-67a6714805f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;cw26&#x27;,\n",
       "                                        FeatureUnion(transformer_list=[(&#x27;word_features&#x27;,\n",
       "                                                                        Pipeline(steps=[(&#x27;ngram_w&#x27;,\n",
       "                                                                                         CountVectorizer(ngram_range=(2,\n",
       "                                                                                                                      3))),\n",
       "                                                                                        (&#x27;tfidf_w&#x27;,\n",
       "                                                                                         TfidfTransformer())])),\n",
       "                                                                       (&#x27;char_features&#x27;,\n",
       "                                                                        Pipeline(steps=[(&#x27;ngram_c&#x27;,\n",
       "                                                                                         CountVectorizer(analyzer=&#x27;char&#x27;,\n",
       "                                                                                                         ngram_range=(2,\n",
       "                                                                                                                      3))),\n",
       "                                                                                        (&#x27;tfidf_c&#x27;,\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       (&#x27;svm&#x27;, SVC(random_state=7))]),\n",
       "             n_jobs=1, param_grid={&#x27;svm__kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "             refit=&#x27;f1&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;f1&#x27;: make_scorer(f1_score),\n",
       "                      &#x27;f1_scored&#x27;: make_scorer(customized_func),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score),\n",
       "                      &#x27;score&#x27;: make_scorer(accuracy_score)},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;cw26&#x27;,\n",
       "                                        FeatureUnion(transformer_list=[(&#x27;word_features&#x27;,\n",
       "                                                                        Pipeline(steps=[(&#x27;ngram_w&#x27;,\n",
       "                                                                                         CountVectorizer(ngram_range=(2,\n",
       "                                                                                                                      3))),\n",
       "                                                                                        (&#x27;tfidf_w&#x27;,\n",
       "                                                                                         TfidfTransformer())])),\n",
       "                                                                       (&#x27;char_features&#x27;,\n",
       "                                                                        Pipeline(steps=[(&#x27;ngram_c&#x27;,\n",
       "                                                                                         CountVectorizer(analyzer=&#x27;char&#x27;,\n",
       "                                                                                                         ngram_range=(2,\n",
       "                                                                                                                      3))),\n",
       "                                                                                        (&#x27;tfidf_c&#x27;,\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       (&#x27;svm&#x27;, SVC(random_state=7))]),\n",
       "             n_jobs=1, param_grid={&#x27;svm__kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "             refit=&#x27;f1&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;f1&#x27;: make_scorer(f1_score),\n",
       "                      &#x27;f1_scored&#x27;: make_scorer(customized_func),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score),\n",
       "                      &#x27;score&#x27;: make_scorer(accuracy_score)},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cw26&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;word_features&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;ngram_w&#x27;,\n",
       "                                                                  CountVectorizer(ngram_range=(2,\n",
       "                                                                                               3))),\n",
       "                                                                 (&#x27;tfidf_w&#x27;,\n",
       "                                                                  TfidfTransformer())])),\n",
       "                                                (&#x27;char_features&#x27;,\n",
       "                                                 Pipeline(steps=[(&#x27;ngram_c&#x27;,\n",
       "                                                                  CountVectorizer(analyzer=&#x27;char&#x27;,\n",
       "                                                                                  ngram_range=(2,\n",
       "                                                                                               3))),\n",
       "                                                                 (&#x27;tfidf_c&#x27;,\n",
       "                                                                  TfidfTransformer())]))])),\n",
       "                (&#x27;svm&#x27;, SVC(random_state=7))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cw26: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;word_features&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;ngram_w&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(2,\n",
       "                                                                              3))),\n",
       "                                                (&#x27;tfidf_w&#x27;,\n",
       "                                                 TfidfTransformer())])),\n",
       "                               (&#x27;char_features&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;ngram_c&#x27;,\n",
       "                                                 CountVectorizer(analyzer=&#x27;char&#x27;,\n",
       "                                                                 ngram_range=(2,\n",
       "                                                                              3))),\n",
       "                                                (&#x27;tfidf_c&#x27;,\n",
       "                                                 TfidfTransformer())]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>word_features</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(2, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>char_features</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(2, 3))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=7)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('cw26',\n",
       "                                        FeatureUnion(transformer_list=[('word_features',\n",
       "                                                                        Pipeline(steps=[('ngram_w',\n",
       "                                                                                         CountVectorizer(ngram_range=(2,\n",
       "                                                                                                                      3))),\n",
       "                                                                                        ('tfidf_w',\n",
       "                                                                                         TfidfTransformer())])),\n",
       "                                                                       ('char_features',\n",
       "                                                                        Pipeline(steps=[('ngram_c',\n",
       "                                                                                         CountVectorizer(analyzer='char',\n",
       "                                                                                                         ngram_range=(2,\n",
       "                                                                                                                      3))),\n",
       "                                                                                        ('tfidf_c',\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       ('svm', SVC(random_state=7))]),\n",
       "             n_jobs=1, param_grid={'svm__kernel': ['linear', 'rbf']},\n",
       "             refit='f1', return_train_score=True,\n",
       "             scoring={'f1': make_scorer(f1_score),\n",
       "                      'f1_scored': make_scorer(customized_func),\n",
       "                      'precision': make_scorer(precision_score),\n",
       "                      'recall': make_scorer(recall_score),\n",
       "                      'score': make_scorer(accuracy_score)},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeccde4e-a4c4-48fc-ba87-d69648af9d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19c3dcf3-0246-47b7-a8fa-c29b691b532f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8424/550586258.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = model.best_estimator_\n",
    "best_model.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a75458ab-b024-4a71-ba02-038dfffb67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aedf6788-051e-4943-9f53-554da2ea9081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huzyfa\\AppData\\Local\\Temp/ipykernel_8424/1153526769.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  sum(pred==y_test)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (2200,), (6,))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8424/1153526769.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__eq__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__ne__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5501\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5502\u001b[1;33m             \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5504\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;31m#  The ambiguous case is object-dtype.  See GH#27803\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    262\u001b[0m                 \u001b[1;34m\"Lengths must match to compare\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: ('Lengths must match to compare', (2200,), (6,))"
     ]
    }
   ],
   "source": [
    "sum(pred==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32a127-b194-4e36-bfd9-ae59936b189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retraining the model with the best estimator\n",
    "best_model = search.best_estimator_\n",
    "best_model.fit(x, y)\n",
    "# predicting of the test set data\n",
    "pred = best_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08510eef-5e7e-46f4-a27e-c47b28be1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# presision is the actual correct prediction divided by total prediction made.\n",
    "# i.e if the model predict that this sample is belongs to class A, what is the \n",
    "# probability that this sample is truthfully belongs to class A\n",
    "# precision = TP/(TP+FP)\n",
    "precision_score = precision_score(y_true=y_test, y_pred=df_test)\n",
    "\n",
    "# recall is the percentage of the samples that belongs to class A, but the model didn't predict them belonging to class A\n",
    "# recall is the number of true positives divided by the total number of true positives and false negatives\n",
    "recall_score = recall_score(y_true=y_test, y_pred=df_test)\n",
    "\n",
    "# f1 score is fatorization of precision and recall, with the goal that if one of them is very bad and the other is very good, \n",
    "# so f1-score will almost  the worse of them\n",
    "# f1-score = 2*(precision*recall)/(precision+recall)\n",
    "f1_score = f1_score(y_true=y_test, y_pred=df_test)\n",
    "\n",
    "# accuracy is the percentage of the correct predictions to the overall predictions\n",
    "accuracy_score = accuracy_score(y_true=y_test, y_pred=df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
